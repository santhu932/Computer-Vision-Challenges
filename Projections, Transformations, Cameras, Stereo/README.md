# A2

All programs have been tested on the SILO servers and can be run by following the exact same formatting as in the instructions,

## Part 1: 3d-to-2d

The program computes the projection matrix for a given 3D world using coordinates from the airport.pts file and simulates an airplane taking off, flying around, and landing. The projection matrix is calculated from the 3D points using the following formula:
![Formula to calculate projection matrix](https://github.com/santhu932/Computer-Vision-Challenges/blob/b70cacf4f393d1297711fdb9ba56fa568d5cfd96/Projections%2C%20Transformations%2C%20Cameras%2C%20Stereo/part1/formula.png)
The given formula calculates the projection matrix (Π), which is used to transform 3D coordinates into 2D coordinates as seen by a camera. This process simulates how a real-world camera would capture a 3D scene. The formula consists of several components:
- A matrix with the focal length (f) represents the camera's intrinsic properties. The focal length determines how the camera "sees" the 3D world in terms of perspective and scale.
- Three rotation matrices for the tilt (α), twist (β), and yaw (γ) angles of the camera. These matrices represent the camera's orientation in 3D space.
- A translation matrix with the camera's location (tx, ty, tz) in 3D space. This matrix represents the camera's position relative to the 3D world.
- The matrix product of these components results in the final projection matrix (Π), which can be used to transform 3D points into their 2D representation as seen by the camera.

![Airport.pts 3D plot for coordinate visualization](https://github.com/santhu932/Computer-Vision-Challenges/blob/b70cacf4f393d1297711fdb9ba56fa568d5cfd96/Projections%2C%20Transformations%2C%20Cameras%2C%20Stereo/part1/airport.png)

The program consists of three main components:
### 1. Projection_matrix():
The "projection_matrix" function accepts focal length, alpha, beta, gamma rotations, and translation values for x, y, and z from the animation function "animate_above." It returns a 2D projection matrix for each animation frame in the context of the 3D world. The function includes helper functions: rotation_matrix_x, rotation_matrix_y, and rotation_matrix_z, which compute the rotation matrices for each plane of rotation in each frame, as specified in the formula above.
A translation matrix 'T' is defined according to the formula and keeps track of the translations in x, y, and z directions in the world. An extra padding row has been added to facilitate conversion to 2D coordinates.
A real-world matrix 'P' is also defined with the focal length representing x and y. This matrix establishes the intrinsic relationship between the 3D coordinates and the 2D coordinates that a camera with focal length 'f' would perceive.

The overall rotation matrix 'R' is calculated by taking the dot product of R_alpha, R_beta, and R_gamma matrices to be incorporated into the final projection matrix calculation. Before being integrated, it is converted to a homogeneous 4x4 matrix by stacking a row and column of zeros.
The projection matrix Pi is computed using the above values by taking the dot product of the homogeneous rotation matrix, the translation matrix, and the camera matrix.

### 2. animate_above():
The "animate_above" function generates frames for the flight simulation animation. In this function, the parameters for translating x, y, and z and the different axes of rotation (yaw, tilt, and twist) are adjusted for each frame to create the overall simulation.
Translations are handled by modifying ty for forward or backward movements, tz for up and down movements, and tx for sideways movements.
Axis rotations are managed by adjusting the yaw, tilt, and twist parameters. The value of pi is used to pass radian values to the matrix, which can be visualized as angles of rotation in the animation. The yaw parameter controls the aircraft's horizontal rotation, the tilt parameter governs its vertical rotation, and the twist parameter manages the aircraft's roll around its central axis.

The animation is divided into sections based on the frame rate, and parameter values are altered for each section of frames.
![Illustration of the entire animation](https://github.com/santhu932/Computer-Vision-Challenges/blob/4ed67221ce4d21a36963e5a60003379777195511/Projections%2C%20Transformations%2C%20Cameras%2C%20Stereo/part1/flightpath.png)

### 3. Plotting
The final component involves plotting the animation. For each point p from the main airport visualization list 'pts3', a new 2D representation is created based on the projection matrix and the current animation frame. The points generated by each animation frame are padded with an extra row and column to create a homogeneous representation, and the dot product of the projected matrix and the homogeneous projected point matrix is computed. If this dot product has a positive z-value, it is considered a point in front of the camera and added to the pts2 list for later plotting.

Each of these points is then plotted on the animation using the FuncAnimation function at a frame rate of 7fps, with a total of 144 frames, and exported as movie.mp4.

## Part 2: Markov Random Fields

The idea of this code is to implement Loopy Belief propagation over a Markov Random field. To do this, we first needed to identify the D, V, and m parts of the formula.

This program reads in two txt files. The first file is the republicrat bribes and the second file is the democran bribes. Together, these two files are used to create the D matrix of the Loopy Belief Propagation so that the cost of a node is based on how much they would need to be bribed in order to be a specified party. The V portion of the algorithm comes from the cost of building a fence in between two houses. If the two houses are both the same party, the cost is zero. If the two houses are of a different party, the cost is 1000. Finally, the m part comes from the message for the previous iteration of the algorithm.

To actually build the algorithm, we had to create dictionaries for D and m. D was made from the two files, and m was made by initializing all messages to 0. For V, we did not directly store anything as is can be calculated easily within the algorithm using an if statement.

We then implemented the actual algorithm. This part was pretty straightforward and just took a little bit of effort debugging to get it working well. On all of the test cases we tried, it ran extremely fast and gave good results. We chose to stop running iterations when the predicted output stopped changing. To do this, we would calculate the assigned values for every house at each iteration and count how many changes between iterations. If no houses changed, we break out of the loop. Since the prediction algorithm is significantly faster than the message passing portion, the run-time did not significantly increase.

The first thing that we did notice about the program is that it does not always find the optimal answer. For example, the optimal solution for the example case in the instructions would be 4500. This could be achieved by only assigning D to the center node and letting all other nodes be R. However, out code finds a local optimum solution of 5510 which was found by setting the leftmost two columns to R and the rest of the houses to D. The reason for this suboptimal solution is because loopy belief propagation is NOT guarenteed to find an optimal solution in the general case. Instead, it can find a solution that is usually "good enough" for any problem.

The other thing that we noticed is that the message values do quickly overflow if left alone. The way that we chose to handle that is to just subtract the minimum value of the messages from every message so that there is always a zero value in the dictionary. This does not guarentee that there will never be an overflow. However, it does drastically slow is down. In every case that we tried, we could run is for thousands of iterations before the values got big enough to overflow. This is more thatn enough time for the algotihm to converge.

The code can be run by typing python3 label_city.py 5 r_bribes.txt d_bribes.txt into the command line.

## Part 3: Inferring depth from stereo

This program implements the stereo matching problem and computes the disparity maps for the given stereo images. Stereo matching involves identifying matching pixels between a pair of images that have been captured from slightly different perspectives. Program solves this issue in two ways, i.e, by Naive Stereo Algorithm and Loopy Belief Propagation which uses Markov Random Fields(MRF) model to estimate the disparity between the pixels of the left and right stereo images. 
Program is run on command line from part3 directory using following command  “python3 stereo.py Aloe/view1.png Aloe/view5.png Aloe/gt.png”. 

### A) Disparity Cost D-Function:
The “disparity_costs” function is employed to calculate the disparity cost at each pixel for every possible disparity values within the MAX_DISPARITY. The function employs a window-based computation method to calculate the cost. This implies that for every pixel in the image, a window of a specific size is employed to compare its intensity values with the corresponding pixel in the other image.
To ensure that the D function can accurately calculate the disparity cost for each pixel, the images are padded. Padding is necessary because the window-based method used in the function requires information from surrounding pixels, including those at the edges of the image. Once the D function computes the cost for every possible disparity value at a pixel, the cost is typically normalized by dividing it with the total number of pixels in the image. Nevertheless, for the Aloe Image, the normalization of the cost matrix is carried out in a distinct manner to produce a more even disparity map. The function creates a three-dimensional array containing the cost for each pixel for all possible disparity values within MAX_DISPARITY. This arrangement of data enables simple access to the cost of any pixel at any disparity value.

### B) Naive Stereo Implementation:
The naive stereo algorithm takes the array generated by the “disparity_costs” function and performs an argmin operation along the axis=2. This operation provides the disparity values at each pixel where the cost is minimum. The disparity map generated by this method is then scaled to a range of 255 for better visualization.

### C) Loopy Belief Propagation:
The "mrf_stereo" function is used to calculate the disparity map using loopy belief propagation on Markov Random Fields. The messages passed between neighboring pixels are calculated based on the previous messages and are stored in four 3D arrays representing messages from the current pixel to all four neighboring pixels for all possible disparity values. This process is repeated for a specified number of iterations. To prevent overflow of values, the messages are normalized by subtracting the mean along the axis = 2. To ensure smoothness of the model, the Potts Model is used as the distance function with ALPHA = 10. For each pixel and possible disparity pair, a fixed cost is assigned if the disparity values are not equal. The total cost is then computed at each pixel by summing the cost calculated from the “disparity_costs” function with all incoming messages. The disparity map is generated by taking the argmin along the axis=2 and scaled to a range of 255 for better visualization.

### D) Results
Following are the errors and disparity maps generated for the example images:

Aloe Image:
Naive stereo technique mean error = 69.32447693595235
MRF stereo technique mean error = 65.90849069209729

![Aloe Naive](/part3/Results/Aloe-naive.png?raw=true "Naive")
![Aloe MRF](part3/Results/Aloe-mrf.png?raw=true "MRF")


Baby1 Image:
Naive stereo technique mean error = 73.74409542714628
MRF stereo technique mean error = 49.87226984854104

![Baby Naive](part3/Results/Baby-naive.png?raw=true "Naive")
![Baby MRF](part3/Results/Baby-mrf.png?raw=true "MRF")


Flowerpots Image:
Naive stereo technique mean error = 266.2157379347312
MRF stereo technique mean error = 248.5796957140207

![Flowerpots Naive](part3/Results/Flowerpots-naive.png?raw=true "Naive")
![Flowerpots MRF](part3/Results/Flowerpots-mrf.png?raw=true "MRF")


### E) Challenges and Future Work:
The choice of window size and MAX_DISPARITY values can have a significant impact on the accuracy of the disparity map. The optimal values depend on the images being analyzed and can vary widely. For example, in the case of the Flowerpots image, higher values for MAX_DISPARITY and window size were used to generate a better disparity map. Determining the optimal number of iterations for the MRF model was another challenge. To minimize the total runtime, vectorization and broadcasting techniques were used with numpy arrays. In future work, an implementation for adaptive window size and disparity values could be explored. This would enable the algorithm to generalize better on a wider range of images.

## Contributions:

Chirantana was responsible for most of problem 1.

Jacob was responsible for most of problem 2.

Santhosh was responsible for most of problem 3.

Bharat helped a little bit with all three problems but was primarily focusing on our final semester project.
